<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SE204 Course Index</title>
    <style>
        body {
            font-family: sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }
        .container {
            width: 80%;
            max-width: 1200px;
            margin: 20px auto;
            background: #fff;
            padding: 25px 40px;
            box-shadow: 0 0 15px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
        }
        h1 {
            text-align: center;
            color: #0056b3; /* Cairo Uni Blue */
            border-bottom: 2px solid #eee;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }
        h2 {
            color: #007bff; /* Lighter Blue */
            border-bottom: 1px solid #eee;
            padding-bottom: 5px;
            margin-top: 30px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
            font-size: 0.9em; /* Adjust font size for better fit */
        }
        th, td {
            border: 1px solid #ddd;
            padding: 10px 12px; /* Adjust padding */
            text-align: left;
            vertical-align: top; /* Align content to top */
        }
        th {
            background-color: #e9ecef;
            font-weight: bold;
            color: #495057;
        }
        tbody tr:nth-child(odd) {
            background-color: #f8f9fa;
        }
        tbody tr:hover {
            background-color: #e2e6ea;
        }
        a {
            color: #0056b3;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        /* Adjust column widths if needed */
        th:nth-child(1), td:nth-child(1) { width: 20%; } /* Module */
        th:nth-child(2), td:nth-child(2) { width: 25%; } /* Main Topics */
        th:nth-child(3), td:nth-child(3) { width: 40%; } /* Key Concepts */
        th:nth-child(4), td:nth-child(4) { width: 15%; } /* Tools */

        ul {
            list-style-type: disc;
            padding-left: 20px;
            margin-top: 0; /* Reduce space above list */
            margin-bottom: 0; /* Reduce space below list */
        }
        li {
             margin-bottom: 5px;
        }
        strong { /* For grading percentages and highlighted concepts */
            /* Keeping default strong styling unless specific color needed */
        }
        .highlight-strong { /* Optional: Style for the bolded concepts */
            font-weight: bold;
        }
        .intro-link {
            display: block;
            text-align: center;
            margin-bottom: 20px;
            font-size: 1.1em;
        }
        code { /* Style for formulas and code */
            background-color: #e9ecef;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: monospace;
            font-size: 0.95em;
        }

    </style>
</head>
<body>
    <div class="container">
        <h1>SE204: Advanced Topics in Information Systems</h1>

        <p class="intro-link">
            This course is part of the
            <a href="https://github.com/astral-fate/Cairo-University-Software-Engineering-Professional-Master-s-Degree" target="_blank" rel="noopener noreferrer">Cairo University Software Engineering Professional Master's Degree</a> program.
        </p>

        <h2>Course Syllabus</h2>
        <table>
            <thead>
                <tr>
                    <th>Module</th>
                    <th>Main Topics</th>
                    <th>Key Concepts</th>
                    <th>Tools</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>
                        <strong><a href="chapters/c1.html">Descriptive Data Analysis and Visualization</a></strong>
                    </td>
                    <td>
                        - Information system definition and elements<br>
                        - Data, information, and knowledge<br>
                        - Types of data (by nature and structure)<br>
                        - Data analysis vs. data analytics<br>
                        - Data analysis techniques<br>
                        - Descriptive data analysis methods<br>
                        - Data visualization techniques
                    </td>
                    <td>
                        - Information systems components (Technology, Task, Person, Structure)<br>
                        - Structured, semi-structured, unstructured data<br>
                        - Quantitative vs. qualitative data<br>
                        - Statistical analysis (descriptive, inferential)<br>
                        - Measures of frequency, central tendency, and dispersion<br>
                        - Data visualization charts (column, bar, line, pie, scatter, etc.)<br>
                        - Pivot tables
                    </td>
                    <td>Power BI</td>
                </tr>
                <tr>
                    <td>
                        <strong><a href="chapters/c2.html">Frequent Pattern Mining</a></strong>
                    </td>
                    <td>
                        - Data Mining Fundamentals & Steps<br>
                        - Data Mining Models (Predictive/Descriptive)<br>
                        - Frequent Pattern Types (Itemsets, Sequential, Structural)<br>
                        - Frequent Itemset Mining Basics<br>
                        - Closed & Maximal Frequent Itemsets<br>
                        - Association Rule Mining<br>
                        - Apriori Algorithm<br>
                        - FP-Growth Algorithm<br>
                        - Python for FPM Intro
                    </td>
                    <td>
                        - Discovering hidden patterns<br>
                        - Itemset (Frequent, Closed, Maximal), k-itemset<br>
                        - Support (Count & Percentage), Confidence<br>
                        - Minimum Support (minsup) Threshold<br>
                        - Association Rules (X→Y, Antecedent, Consequent)<br>
                        - Apriori Principle<br>
                        - Apriori Algorithm Steps & Drawbacks<br>
                        - FP-Growth Algorithm (FP-Tree, Conditional Base/Tree, Steps, Advantages/Disadvantages)<br>
                        - Python Environment Setup
                    </td>
                    <td>Python, pandas, mlxtend</td>
                </tr>
                <tr>
                    <td>
                        <strong><a href="chapters/c3.html">Machine Learning 1: Introduction</a></strong>
                    </td>
                    <td>
                        - Machine learning fundamentals<br>
                        - Supervised vs. unsupervised learning<br>
                        - Training and testing models<br>
                        - <strong class="highlight-strong">ML vs Conventional Programming</strong><br>
                        - <strong class="highlight-strong">ML Concepts</strong><br>
                        - <strong class="highlight-strong">Types of ML Overview</strong>
                    </td>
                    <td>
                        - Learning from data<br>
                        - <strong class="highlight-strong">ML vs Rule-based systems</strong><br>
                        - <strong class="highlight-strong">AI / Deep Learning Context</strong><br>
                        - <strong class="highlight-strong">Reasons for ML Growth</strong><br>
                        - <strong class="highlight-strong">Labeled vs. Unlabeled Data</strong><br>
                        - <strong class="highlight-strong">Training/Testing Sets</strong><br>
                        - <strong class="highlight-strong">Overfitting/Underfitting</strong><br>
                        - <strong class="highlight-strong">Supervised, Unsupervised, Reinforcement Learning (definitions & goals)</strong>
                    </td>
                    <td> </td> <!-- No specific tool mentioned in source for this module -->
                </tr>
                <tr>
                    <td>
                         <strong><a href="chapters/c4.html">Machine Learning 2: Linear Regression & Clustering</a></strong>
                    </td>
                    <td>
                        - Classification algorithms<br>
                        - <strong class="highlight-strong">Binary vs Multi-class</strong><br>
                        - <strong class="highlight-strong">Logistic Regression Focus</strong><br>
                        - <strong class="highlight-strong">Clustering Algorithms (Unsupervised)</strong><br>
                        - K-Means Algorithm Focus<br>
                        - Dimensionality Reduction Overview
                    </td>
                    <td>
                        - <strong class="highlight-strong">Task:</strong> Assigning data points to predefined categories<br>
                        - <strong class="highlight-strong">Types:</strong> Binary (2 categories) vs. Multi-class (>2 categories)<br>
                        - <strong class="highlight-strong">Classifier:</strong> The model performing classification<br>
                        - Examples: Spam detection, Medical Diagnosis, Image Recognition<br>
                        - <strong class="highlight-strong">Logistic Regression Details:</strong><br>
                        &nbsp;&nbsp;- Predicts probability for categories<br>
                        &nbsp;&nbsp;- <strong class="highlight-strong">Function Map:</strong> Sigmoid (binary: <code>ŷ = 1 / (1 + e⁻ᶻ)</code>) or Softmax (multi-class)<br>
                        &nbsp;&nbsp;- <strong class="highlight-strong">Model Performance:</strong> Loss Function (e.g., Binary Cross-Entropy: <code>L(y, ŷ) = −[y log(ŷ) + (1−y)log(1−ŷ)]</code>)<br>
                        &nbsp;&nbsp;- <strong class="highlight-strong">Optimization:</strong> Uses Gradient Descent algorithm to update coefficients & minimize loss<br>
                        - <strong class="highlight-strong">Clustering Task:</strong> Grouping similar data points without predefined labels<br>
                        - <strong class="highlight-strong">K-Means Algorithm Steps:</strong><br>
                        &nbsp;&nbsp;1. Initialize K centroids<br>
                        &nbsp;&nbsp;2. Assign points to nearest centroid (e.g., using Euclidean distance: <code>D = √((xₚ-xᵢ)²+(yₚ-yᵢ)²)</code>)<br>
                        &nbsp;&nbsp;3. Update centroids (calculate mean of assigned points)<br>
                        &nbsp;&nbsp;4. Repeat 2-3 until convergence (centroids stabilize)<br>
                        - <strong class="highlight-strong">Dimensionality Reduction:</strong> Reducing number of features (brief mention)
                    </td>
                    <td>Python (Scikit-learn etc.)</td>
                </tr>
             
               
                <tr>
                    <td>
                         <strong><a href="chapters/c5.html">Machine Learning 3: Practical Examples</a></strong>
                    </td>
                    <td>
                        - Practical Implementation of K-Means Clustering in Python<br>
                        - Practical Implementation of Linear Regression in Python<br>
                        - Practical Implementation of Logistic Regression in Python<br>
                      
                       
                    </td>
                    <td>
                       <ul>
                            <li><strong class="highlight-strong">K-Means Practical:</strong> Python code for partitioning data into 'k' clusters using centroids.</li>
                            <li><strong class="highlight-strong">Linear Regression Practical:</strong> Python code for predicting continuous values, finding slope/intercept, evaluating with MSE.</li>
                            <li><strong class="highlight-strong">Logistic Regression Practical:</strong> Python code for binary classification (pass/fail example).</li>
            
                       </ul>
                    </td>
                    <td>
                        Python<br>
                        <code>numpy</code><br>
                        <code>matplotlib.pyplot</code><br>
                        <code>scikit-learn</code>:
                         <ul>
                            <li><code>KMeans</code></li>
                            <li><code>LinearRegression</code></li>
                            <li><code>LogisticRegression</code></li>
                            <li><code>mean_squared_error</code></li>
                         </ul>
                    </td>
                </tr>
                
                <tr>
                    <td>
                         <strong><a href="chapters/c6.html">Machine Learning 4: Deep Learning</a></strong>
                    </td>
                    <td>
                        - Neural Networks fundamentals<br>
                        - Deep Neural Networks (DNNs)<br>
                        - Feature extraction in Deep Learning<br>
                        - Comparison with traditional ML<br>
                        - Deep Learning applications<br>
                        - Neural Network architecture
                    </td>
                    <td>
                       <ul>
                            <li><strong class="highlight-strong">Deep Learning (DL):</strong> Subset of ML based on ANNs with multiple hidden layers ("deep"). Learns complex patterns.</li>
                            <li><strong class="highlight-strong">Artificial Neural Networks (ANNs):</strong> Inspired by biological neurons (cell body, dendrites, axon). Composed of layers (Input, Hidden, Output) with weighted connections adjusted during training.</li>
                            <li><strong class="highlight-strong">Machine Learning vs. Deep Learning:</strong>
                                <ul>
                                    <li><i>Feature Extraction:</i> ML often manual, DL automatic.</li>
                                    <li><i>Data/Compute Needs:</i> DL > ML.</li>
                                    <li><i>Task Complexity:</i> DL excels at complex tasks (vision, NLP).</li>
                                </ul>
                            </li>
                            <li><strong class="highlight-strong">ANN vs. DNN:</strong>
                                <ul>
                                    <li>ANN is general, can be shallow (e.g., 1 hidden layer).</li>
                                    <li>DNN implies deep (2+ hidden layers). All DNNs are ANNs.</li>
                                </ul>
                            </li>
                       </ul>
                    </td>
                    <td>
                        Python<br>
                        <code>TensorFlow</code><br>
                        <code>Keras</code><br>
                        <code>PyTorch</code>
                    </td>
                </tr>
            </tbody>
        </table>

        <h2>Grading</h2>
        <ul>
            <li><strong>60%</strong>: Attendance, Assignments, Quizzes, Midterm Exam</li>
            <li><strong>40%</strong>: Final Exam</li>
        </ul>
    </div>
</body>
</html>
